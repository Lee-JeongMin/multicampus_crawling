{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin, urlparse, parse_qs\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 뉴스 속보 페이지에서 정치/경제/사회 기사 링크 수집 \n",
    "링크 : https://news.naver.com/main/ranking/popularDay.nhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 수집해야할 날짜의 범위\n",
    "def news_link_crawler(date_range, base_url, params):\n",
    "\n",
    "    ranking_news_list = []\n",
    "    \n",
    "    for date in date_range:\n",
    "        params['date'] = date\n",
    "#         print('date', date)\n",
    "\n",
    "        resp = requests.get(base_url,params=params)\n",
    "        soup = BeautifulSoup(resp.text,'lxml')\n",
    "        ranking_wrap = soup.select('div.ranking_section li dt a')\n",
    "\n",
    "        date_news_dict = {}\n",
    "        news_list = []\n",
    "\n",
    "        # 정치, 경제, 사회로 범위 한정\n",
    "        for ranking in ranking_wrap[:-15]:\n",
    "            news_list.append(urljoin(base_url,ranking.get('href')))\n",
    "\n",
    "        date_news_dict[date] = news_list\n",
    "\n",
    "        ranking_news_list.append(date_news_dict)\n",
    "    \n",
    "    return ranking_news_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 뉴스 기사에서 기사제목/ 섹션 / 요약봇의 기사요약 내용 / 이미지 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def news_body_crawler(ranking_news_list):\n",
    "    finally_news_list = []\n",
    "\n",
    "    for ranking_list in ranking_news_list:\n",
    "        for yyyymmdd, ranking in ranking_list.items():\n",
    "            for ranking_news in ranking:\n",
    "\n",
    "                news_dict = {}\n",
    "                \n",
    "                resp_news = requests.get(ranking_news)\n",
    "                soup_news = BeautifulSoup(resp_news.text)\n",
    "\n",
    "                # 기사 제목\n",
    "                header_wrap = soup_news.select('div.article_info h3')\n",
    "                title = header_wrap[0].text\n",
    "\n",
    "                # 섹션\n",
    "                section = soup_news.find('em', class_='guide_categorization_item')\n",
    "\n",
    "                # 기사 ID\n",
    "                parsed_url = urlparse(ranking_news)\n",
    "                qs = parse_qs(parsed_url.query)\n",
    "                oid = qs['oid'][0]\n",
    "                aid = qs['aid'][0]\n",
    "#                 print(oid, aid)\n",
    "\n",
    "                # 내용\n",
    "                summary_url = 'https://tts.news.naver.com/article/{}/{}/summary'.format(oid, aid)\n",
    "                resp_summary = requests.get(summary_url)\n",
    "                soup_summary = BeautifulSoup(resp_summary.text)\n",
    "                summary = soup_summary.text.split(':')[-1].replace('}','').replace(\"\\\\\",\"\")\n",
    "\n",
    "                news_dict = {\n",
    "                    '날짜' : yyyymmdd[:4]+'-'+yyyymmdd[4:6]+'-'+yyyymmdd[6:],\n",
    "                    'title' : title,\n",
    "                    'category' : section.text,\n",
    "                    'summary' : summary.replace('\"','')\n",
    "                }\n",
    "\n",
    "                # 이미지 \n",
    "                image_wrap = soup_news.find('span', class_=\"end_photo_org\")\n",
    "\n",
    "                if image_wrap:\n",
    "                    news_dict['img'] = image_wrap.find('img').get('src')\n",
    "                finally_news_list.append(news_dict)\n",
    "                \n",
    "    return finally_news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_to_csv(finally_news_list):\n",
    "    df = pd.DataFrame(finally_news_list)\n",
    "    df.to_csv('finally_naver_news_crawling.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\ProgramData\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "date_range = (pd.date_range(start='20200501', end=datetime.date.today())).strftime(\"%Y%m%d\").tolist()\n",
    "base_url= 'https://news.naver.com/main/ranking/popularDay.nhn'\n",
    "params = {\n",
    "    'rankingType' : 'popular_day',\n",
    "    'date' : ''\n",
    "}\n",
    "\n",
    "NewsList = news_link_crawler(date_range, base_url, params)\n",
    "# NewsList[0]\n",
    "\n",
    "FinallyNewsList = news_body_crawler(NewsList)\n",
    "# len(finally_news_list),finally_news_list[0]\n",
    "\n",
    "save_df_to_csv(FinallyNewsList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
