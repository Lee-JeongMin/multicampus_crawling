{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode, unquote, quote_plus\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serviceKey': '13nWfyvckU06jS8j02cgKEde9gF7+9BZ+OFcpgpuu/nNRbR64QYGlNEzN7b/9D4RI3uFKkJ97YT9mf5X3FMIUA==',\n",
       " 'numOfRows': '10',\n",
       " 'pageNo': '1',\n",
       " 'dataCd': 'ASOS',\n",
       " 'dateCd': 'HR',\n",
       " 'stnIds': '108',\n",
       " 'schListCnt': '10',\n",
       " 'endDt': '20200101',\n",
       " 'endHh': '01',\n",
       " 'startHh': '01',\n",
       " 'startDt': '20100101',\n",
       " 'dataType': 'JSON'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "url = urlparse(\"http://apis.data.go.kr/1360000/AsosHourlyInfoService/getWthrDataList?serviceKey=13nWfyvckU06jS8j02cgKEde9gF7%2B9BZ%2BOFcpgpuu%2FnNRbR64QYGlNEzN7b%2F9D4RI3uFKkJ97YT9mf5X3FMIUA%3D%3D&numOfRows=10&pageNo=1&dataCd=ASOS&dateCd=HR&stnIds=108&schListCnt=10&endDt=20200101&endHh=01&startHh=01&startDt=20100101&dataType=JSON\")\n",
    "par_dic = parse_qs(url.query)\n",
    "for key in par_dic:\n",
    "    par_dic[key] = par_dic[key][0]\n",
    "par_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_data(start_date, start_hour,end_date,end_hour):\n",
    "    start_date=start_date\n",
    "    start_hour=start_hour\n",
    "    end_date=end_date\n",
    "    end_hour=end_hour\n",
    "    url='http://apis.data.go.kr/1360000/AsosHourlyInfoService/getWthrDataList'\n",
    "\n",
    "    \n",
    "    params={'serviceKey': '13nWfyvckU06jS8j02cgKEde9gF7+9BZ+OFcpgpuu/nNRbR64QYGlNEzN7b/9D4RI3uFKkJ97YT9mf5X3FMIUA==',\n",
    "     'numOfRows': '10',\n",
    "     'pageNo': '1',\n",
    "     'dataCd': 'ASOS',\n",
    "     'dateCd': 'HR',\n",
    "     'stnIds': '108',\n",
    "     'schListCnt': '10',\n",
    "     'endDt': end_date,\n",
    "     'endHh': end_hour,\n",
    "     'startHh': start_hour,\n",
    "     'startDt': start_date,\n",
    "     'dataType': 'JSON'\n",
    "           }\n",
    "\n",
    "    resp = requests.get(url, params=params)\n",
    "    #result= json.loads(resp.text)\n",
    "\n",
    "    return resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serviceKey': '13nWfyvckU06jS8j02cgKEde9gF7+9BZ+OFcpgpuu/nNRbR64QYGlNEzN7b/9D4RI3uFKkJ97YT9mf5X3FMIUA==',\n",
       " 'numOfRows': '10',\n",
       " 'pageNo': '1',\n",
       " 'dataCd': 'ASOS',\n",
       " 'dateCd': 'DAY',\n",
       " 'startDt': '20100101',\n",
       " 'endDt': '20100102',\n",
       " 'stnIds': '108'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "url = urlparse(\"http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey=13nWfyvckU06jS8j02cgKEde9gF7%2B9BZ%2BOFcpgpuu%2FnNRbR64QYGlNEzN7b%2F9D4RI3uFKkJ97YT9mf5X3FMIUA%3D%3D&numOfRows=10&pageNo=1&dataCd=ASOS&dateCd=DAY&startDt=20100101&endDt=20100102&stnIds=108\")\n",
    "par_dic = parse_qs(url.query)\n",
    "for key in par_dic:\n",
    "    par_dic[key] = par_dic[key][0]\n",
    "par_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_data(start_date,end_date):\n",
    "    start_date=start_date\n",
    "    end_date=end_date\n",
    "    url='http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList'\n",
    "\n",
    "    \n",
    "    params={'serviceKey': unquote('13nWfyvckU06jS8j02cgKEde9gF7%2B9BZ%2BOFcpgpuu%2FnNRbR64QYGlNEzN7b%2F9D4RI3uFKkJ97YT9mf5X3FMIUA%3D%3D'),\n",
    "            'numOfRows': '200',\n",
    "            'pageNo': '1',\n",
    "            'dataCd': 'ASOS',\n",
    "            'dateCd': 'DAY',\n",
    "            'startDt': start_date,\n",
    "            'endDt': end_date,\n",
    "            'stnIds': '108',\n",
    "            'dataType':'JSON'\n",
    "           }\n",
    "\n",
    "    resp = requests.get(url, params=params)\n",
    "    result= json.loads(resp.text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_DataFrame(result):\n",
    "    total_data=result['response']['body']['items']['item']\n",
    "    \n",
    "    result = {'날짜':[],\n",
    "              '최저기온':[],\n",
    "              '최고기온':[],\n",
    "              '비':[],\n",
    "              '강수량':[],\n",
    "              '날씨':[],\n",
    "             }\n",
    "    for data in total_data:\n",
    "        avg = (data['minTa']+data['maxTa'])/2\n",
    "        result['날짜'].append(data['tm'])\n",
    "        result['최저기온'].append(data['minTa'])\n",
    "        result['최고기온'].append(data['maxTa'])\n",
    "        avg = (data['minTa']+data['maxTa'])/2\n",
    "        if data['sumRn']>0:\n",
    "            result['비'].append('O')\n",
    "            result['날씨'].append('비')\n",
    "        else:\n",
    "            if avg<10:\n",
    "                result['날씨'].append('추위')\n",
    "            elif avg<20:\n",
    "                result['날씨'].append('쌀쌀')\n",
    "            else:\n",
    "                result['날씨'].append('더위')\n",
    "            result['비'].append('X')\n",
    "        result['강수량'].append(data['sumRn'])\n",
    "        \n",
    "        \n",
    "    df=pd.DataFrame(result)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_today(data):\n",
    "    url = 'https://www.weatheri.co.kr/forecast/forecast01.php'\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content, from_encoding='utf-8')\n",
    "    attrs={'width':'615',\n",
    "      'border':'0',\n",
    "      'cellpadding':'1',\n",
    "      'cellspacing':'1',\n",
    "       'bgcolor':'#BCBFC2'\n",
    "      }\n",
    "    inner_table = soup.find('table',attrs=attrs)\n",
    "    date = inner_table.select('td b')[0].text\n",
    "    date = '2020-{0}-{1}'.format(date.split()[0][:2],date.split()[1][:2])\n",
    "    high = inner_table.select('table tr td b font')[0].text\n",
    "    high = high.replace('˚C','')\n",
    "    low = inner_table.select('table tr td b font')[0].text\n",
    "    low = low.replace('˚C','')\n",
    "    sum_rain=inner_table.select('table tr td font')[-1].text\n",
    "    avg = (int(low)+int(high))/2\n",
    "    if sum_rain !='- mm':\n",
    "        rain='O',\n",
    "        sum_rain = 0\n",
    "        weather = '비'\n",
    "    else:\n",
    "        rain='X'\n",
    "        sum_rain.split()[1][:-2]\n",
    "        if avg<10:\n",
    "            weather = '추위'\n",
    "        elif avg<20:\n",
    "            weather = '쌀쌀'\n",
    "        else:\n",
    "            weather = '더위'\n",
    "    \n",
    "    new_data=pd.DataFrame({'날짜':[date],\n",
    "             '최저기온':[low],\n",
    "             '최고기온':[high],\n",
    "             '비':[rain],\n",
    "             '강수량':[sum_rain],\n",
    "             '날씨':[weather]})\n",
    "    \n",
    "    data = data.append(new_data,ignore_index=True)\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            날짜  최저기온  최고기온     비   강수량  날씨\n",
      "0   2020-05-01  16.4  26.2     X   0.0  더위\n",
      "1   2020-05-02    18  23.9     X   0.0  더위\n",
      "2   2020-05-03    17  27.4     X   0.0  더위\n",
      "3   2020-05-04  14.8  25.3     X   0.0  더위\n",
      "4   2020-05-05  13.1  19.3     X   0.0  쌀쌀\n",
      "5   2020-05-06  11.1  27.6     X   0.0  쌀쌀\n",
      "6   2020-05-07  14.9  26.5     X   0.0  더위\n",
      "7   2020-05-08  14.3  27.3     O   2.3   비\n",
      "8   2020-05-09  12.7  16.8     O  24.4   비\n",
      "9   2020-05-10  12.8  16.6     O   1.3   비\n",
      "10  2020-05-11  12.4    22     O   3.4   비\n",
      "11  2020-05-12  10.5  18.9     O   0.7   비\n",
      "12  2020-05-13  10.2  21.8     X   0.0  쌀쌀\n",
      "13  2020-05-14  12.4  25.4     X   0.0  쌀쌀\n",
      "14  2020-05-15  14.1  20.2     O  12.0   비\n",
      "15  2020-05-16    15  20.3     O   2.5   비\n",
      "16  2020-05-17  14.6  24.9     X   0.0  쌀쌀\n",
      "17  2020-05-18  13.2  26.8     O  29.8   비\n",
      "18  2020-05-19  10.1  17.1     O  19.0   비\n",
      "19  2020-05-20   9.2  20.1     X   0.0  쌀쌀\n",
      "20  2020-05-21  10.9  22.9     X   0.0  쌀쌀\n",
      "21  2020-05-22  14.8  22.7     X   0.0  쌀쌀\n",
      "22  2020-05-23  16.6    25     X   0.0  더위\n",
      "23  2020-05-24  14.3  20.2     O  14.5   비\n",
      "24  2020-05-25  13.7  21.3     X   0.0  쌀쌀\n",
      "25  2020-05-26  12.7  22.9     O   1.5   비\n",
      "26  2020-05-27  11.8  23.9     X   0.0  쌀쌀\n",
      "27  2020-05-28  14.2  23.4     X   0.0  쌀쌀\n",
      "28  2020-05-29  14.6  27.6     X   0.0  더위\n",
      "29  2020-05-30  16.5    30     X   0.0  더위\n",
      "30  2020-05-31  17.6    28     O   1.0   비\n",
      "31  2020-06-01  16.6  24.5     O   0.4   비\n",
      "32  2020-06-02  14.8  21.8     O   2.0   비\n",
      "33  2020-06-03  17.6  28.4     X   0.0  더위\n",
      "34  2020-06-04  19.7  26.5     O   0.2   비\n",
      "35  2020-06-05  18.4  28.7     X   0.0  더위\n",
      "36  2020-06-06  19.2  30.9     X   0.0  더위\n",
      "37  2020-06-07  19.2  29.2     X   0.0  더위\n",
      "38  2020-06-08  19.8    32     X   0.0  더위\n",
      "39  2020-06-09  20.3  32.8     X   0.0  더위\n",
      "40  2020-06-10    31    31  (O,)   0.0   비\n"
     ]
    }
   ],
   "source": [
    "result=get_daily_data('20200501','20200609')\n",
    "output=data_to_DataFrame(result)\n",
    "d=append_today(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_weather(weather):\n",
    "    header = {'User-Agent': 'Mozilla/5.0'}    # melon 크롤링 시 header값 필요\n",
    "    base_url = 'https://www.melon.com/dj/djfinder/djfinder_inform.htm'\n",
    "\n",
    "    params = {\n",
    "        'djSearchKeyword':weather\n",
    "    }\n",
    "    resp = requests.get(base_url,headers=header,params=params)\n",
    "    soup = BeautifulSoup(resp.text)\n",
    "    #print(resp)\n",
    "    #soup\n",
    "    # playlist의 seq를 뽑아 리스트에 넣기\n",
    "    ply_list_dj = soup.select('div.service_list_play.d_djcol_list li')\n",
    "    #print(ply_list_dj)\n",
    "    seq = []\n",
    "    for li in ply_list_dj:\n",
    "        a_tag = li.find('a')\n",
    "        #print(a_tag)\n",
    "        par = a_tag.get('href')\n",
    "        #print(par)\n",
    "        seq.append(int(par[-12:-3]))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_and_singer(seq):\n",
    "    titles = []         # 각 플레이리스트별로 리스트 초기화\n",
    "    singers = []\n",
    "    song = []\n",
    "    likes = []\n",
    "    for i in range(len(seq)):\n",
    "        new_url = 'https://www.melon.com/mymusic/dj/mymusicdjplaylistview_inform.htm'\n",
    "        new_params = {\n",
    "        'plylstSeq': seq[i]\n",
    "        }\n",
    "        hdr={'User-Agent': 'Mozilla/5.0'}\n",
    "        new_resp = requests.get(new_url,headers=hdr,params=new_params)\n",
    "        new_soup = BeautifulSoup(new_resp.text)\n",
    "\n",
    "        song_list = new_soup.find_all('div',class_='wrap_song_info')\n",
    "        #     print(song_list)\n",
    "\n",
    "        for wrap in song_list:\n",
    "            title = wrap.find('div',class_='ellipsis rank01')\n",
    "            singer = wrap.find('div',class_='ellipsis rank02')\n",
    "            if singer != None:\n",
    "                leng = round(len(singer.text)/2)\n",
    "                singers.append(singer.text[:leng].strip())\n",
    "        #     print(singers)\n",
    "            if title != None:\n",
    "                titles.append(title.text.strip())\n",
    "        # print(titles,len(titles))    \n",
    "        # print(singers,len(singers))\n",
    "#         print('\\n')\n",
    "        for ts in range(len(titles)):\n",
    "            song.append((titles[ts],singers[ts]))\n",
    "        #     song = list(zip(titles,singers))\n",
    "        likes = likes_num(seq[i])\n",
    "        for tsl in range(len(likes)):\n",
    "            if song[tsl] in info:\n",
    "                info[song[tsl]] = likes[tsl]+100\n",
    "            else:\n",
    "                info[song[tsl]] = likes[tsl]\n",
    "    return info\n",
    "\n",
    "        #     print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likes_num(sq):\n",
    "    likes = []\n",
    "    new_url = 'https://www.melon.com/mymusic/dj/mymusicdjplaylistview_inform.htm'\n",
    "    new_params = {\n",
    "        'plylstSeq': sq\n",
    "    }                                       # 각 플레이리스트 url 생성\n",
    "    header = {'User-Agent': 'Mozilla/5.0'}\n",
    "    new_resp = requests.get(new_url,headers = header,params=new_params)\n",
    "    new_soup = BeautifulSoup(new_resp.text)\n",
    "    song_in_plylist = new_soup.select('div.wrap button')\n",
    "\n",
    "    # print(song_in_plylist)\n",
    "    song_no = []\n",
    "    for button in song_in_plylist:\n",
    "        no = button.get('data-song-no')\n",
    "        if no != None:\n",
    "            song_no.append(no)\n",
    "    #print(song_no)\n",
    "    song_no_select = song_no[0]\n",
    "    for s in range(1,len(song_no)):\n",
    "        song_no_select = song_no_select +','+str(song_no[s])\n",
    "    ply_url = 'https://www.melon.com/commonlike/getSongLike.json'\n",
    "    # print(song_no_select)\n",
    "    ply_params = {\n",
    "        \"contsIds\": song_no_select\n",
    "        }\n",
    "    referer = 'https://www.melon.com/mymusic/dj/mymusicdjplaylistview_inform.htm?plylstSeq='+str(sq)\n",
    "    # print(referer)\n",
    "\n",
    "    hd = {\n",
    "        'User-Agent': 'Mozilla/5.0',\n",
    "        'referer':referer\n",
    "        }\n",
    "    ply_resp = requests.get(ply_url,headers=hd,params=ply_params)\n",
    "    # ply_resp\n",
    "    result= json.loads(ply_resp.text)\n",
    "    # result\n",
    "    extract = result['contsLike']\n",
    "    # print(extract)\n",
    "    for i in range(len(song_no)):\n",
    "        likes.append(extract[i]['SUMMCNT'])\n",
    "    return likes\n",
    "    # likes\n",
    "\n",
    "# likes_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'날짜': ['2020-05-01', '2020-05-01', '2020-05-01', '2020-05-01', '2020-05-01', '2020-05-02', '2020-05-02', '2020-05-02', '2020-05-02', '2020-05-02', '2020-05-03', '2020-05-03', '2020-05-03', '2020-05-03', '2020-05-03', '2020-05-04', '2020-05-04', '2020-05-04', '2020-05-04', '2020-05-04', '2020-05-05', '2020-05-05', '2020-05-05', '2020-05-05', '2020-05-05', '2020-05-06', '2020-05-06', '2020-05-06', '2020-05-06', '2020-05-06', '2020-05-07', '2020-05-07', '2020-05-07', '2020-05-07', '2020-05-07', '2020-05-08', '2020-05-08', '2020-05-08', '2020-05-08', '2020-05-08', '2020-05-09', '2020-05-09', '2020-05-09', '2020-05-09', '2020-05-09', '2020-05-10', '2020-05-10', '2020-05-10', '2020-05-10', '2020-05-10', '2020-05-11', '2020-05-11', '2020-05-11', '2020-05-11', '2020-05-11', '2020-05-12', '2020-05-12', '2020-05-12', '2020-05-12', '2020-05-12', '2020-05-13', '2020-05-13', '2020-05-13', '2020-05-13', '2020-05-13', '2020-05-14', '2020-05-14', '2020-05-14', '2020-05-14', '2020-05-14', '2020-05-15', '2020-05-15', '2020-05-15', '2020-05-15', '2020-05-15', '2020-05-16', '2020-05-16', '2020-05-16', '2020-05-16', '2020-05-16', '2020-05-17', '2020-05-17', '2020-05-17', '2020-05-17', '2020-05-17', '2020-05-18', '2020-05-18', '2020-05-18', '2020-05-18', '2020-05-18', '2020-05-19', '2020-05-19', '2020-05-19', '2020-05-19', '2020-05-19', '2020-05-20', '2020-05-20', '2020-05-20', '2020-05-20', '2020-05-20', '2020-05-21', '2020-05-21', '2020-05-21', '2020-05-21', '2020-05-21', '2020-05-22', '2020-05-22', '2020-05-22', '2020-05-22', '2020-05-22', '2020-05-23', '2020-05-23', '2020-05-23', '2020-05-23', '2020-05-23', '2020-05-24', '2020-05-24', '2020-05-24', '2020-05-24', '2020-05-24', '2020-05-25', '2020-05-25', '2020-05-25', '2020-05-25', '2020-05-25', '2020-05-26', '2020-05-26', '2020-05-26', '2020-05-26', '2020-05-26', '2020-05-27', '2020-05-27', '2020-05-27', '2020-05-27', '2020-05-27', '2020-05-28', '2020-05-28', '2020-05-28', '2020-05-28', '2020-05-28', '2020-05-29', '2020-05-29', '2020-05-29', '2020-05-29', '2020-05-29', '2020-05-30', '2020-05-30', '2020-05-30', '2020-05-30', '2020-05-30', '2020-05-31', '2020-05-31', '2020-05-31', '2020-05-31', '2020-05-31', '2020-06-01', '2020-06-01', '2020-06-01', '2020-06-01', '2020-06-01', '2020-06-02', '2020-06-02', '2020-06-02', '2020-06-02', '2020-06-02', '2020-06-03', '2020-06-03', '2020-06-03', '2020-06-03', '2020-06-03', '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-04', '2020-06-05', '2020-06-05', '2020-06-05', '2020-06-05', '2020-06-05', '2020-06-06', '2020-06-06', '2020-06-06', '2020-06-06', '2020-06-06', '2020-06-07', '2020-06-07', '2020-06-07', '2020-06-07', '2020-06-07', '2020-06-08', '2020-06-08', '2020-06-08', '2020-06-08', '2020-06-08', '2020-06-09', '2020-06-09', '2020-06-09', '2020-06-09', '2020-06-09', '2020-06-10', '2020-06-10', '2020-06-10', '2020-06-10', '2020-06-10'], '노래': ['Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', 'Plastic Heart', 'Inn', 'Outro', 'Comfortable', 'Slide', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', 'Toxic', 'Wasted Summer', 'Lie To Me', 'Freedom', '빨간 맛 (Red Flavor)', '사랑은 언제나 목마르다', '내 입술... 따뜻한 커피처럼', '오늘 헤어졌어요', '희재', '이별살이'], '가수': ['Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', 'Land of Peace', '주영', 'Tom Misch', 'Lauv', 'James Bay', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', 'Glaceo, Cristina Lizzul', 'teamwork, Loote, John K', 'Marphil, Yann Muller, Sylow', 'Kygo, Zak Abel', 'Red Velvet (레드벨벳)', '유미', '샵', '윤하 (YOUNHA)', '성시경', '린'], '좋아요 수': [481718, 283256, 182396, 181091, 95193, 481718, 283256, 182396, 181091, 95193, 481718, 283256, 182396, 181091, 95193, 481718, 283256, 182396, 181091, 95193, 183543, 28655, 25391, 6547, 4738, 183543, 28655, 25391, 6547, 4738, 481718, 283256, 182396, 181091, 95193, 4836, 3972, 2428, 1391, 1190, 4836, 3972, 2428, 1391, 1190, 4836, 3972, 2428, 1391, 1190, 4836, 3972, 2428, 1391, 1190, 4836, 3972, 2428, 1391, 1190, 183543, 28655, 25391, 6547, 4738, 183543, 28655, 25391, 6547, 4738, 4836, 3972, 2428, 1391, 1190, 4836, 3972, 2428, 1391, 1190, 183543, 28655, 25391, 6547, 4738, 4836, 3972, 2428, 1391, 1190, 4836, 3972, 2428, 1391, 1190, 183543, 28655, 25391, 6547, 4738, 183543, 28655, 25391, 6547, 4738, 183543, 28655, 25391, 6547, 4738, 481718, 283256, 182396, 181091, 95193, 4836, 3972, 2428, 1391, 1190, 183543, 28655, 25391, 6547, 4737, 4836, 3972, 2428, 1391, 1190, 183543, 28655, 25391, 6547, 4737, 183543, 28655, 25391, 6547, 4737, 481718, 283256, 182396, 181091, 95193, 481718, 283256, 182396, 181091, 95193, 4836, 3972, 2428, 1391, 1190, 4836, 3972, 2428, 1391, 1190, 4836, 3972, 2428, 1391, 1190, 481718, 283256, 182396, 181091, 95193, 4836, 3972, 2428, 1391, 1190, 481718, 283256, 182396, 181091, 95193, 481718, 283256, 182396, 181091, 95193, 481718, 283256, 182396, 181091, 95193, 481718, 283256, 182396, 181091, 95193, 481718, 283257, 182396, 181091, 95193, 4836, 3972, 2428, 1391, 1190]}\n"
     ]
    }
   ],
   "source": [
    "result_={\n",
    "        '날짜':[],\n",
    "        '노래':[],\n",
    "        '가수':[],\n",
    "        '좋아요 수':[]\n",
    "    }\n",
    "for k in range(len(d['날씨'])):\n",
    "    info = {}\n",
    "    date = d['날짜'][k]\n",
    "    curr_seq = enter_weather(d['날씨'][k])\n",
    "    print(d['날짜'][k],d['날씨'][k])\n",
    "#     print(curr_seq)\n",
    "    result_info = title_and_singer(curr_seq)\n",
    "    result_info = sorted(result_info.items(), key=lambda x: x[1], reverse=True)\n",
    "    for j in range(5):\n",
    "        result_['날짜'].append(date),\n",
    "        result_['노래'].append(result_info[j][0][0]),\n",
    "        result_['가수'].append(result_info[j][0][1]),\n",
    "        result_['좋아요 수'].append(result_info[j][1])\n",
    "print(result_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result_)\n",
    "df.to_csv('weather_melon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>노래</th>\n",
       "      <th>가수</th>\n",
       "      <th>좋아요 수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Toxic</td>\n",
       "      <td>Glaceo, Cristina Lizzul</td>\n",
       "      <td>481718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Wasted Summer</td>\n",
       "      <td>teamwork, Loote, John K</td>\n",
       "      <td>283256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Lie To Me</td>\n",
       "      <td>Marphil, Yann Muller, Sylow</td>\n",
       "      <td>182396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Freedom</td>\n",
       "      <td>Kygo, Zak Abel</td>\n",
       "      <td>181091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>빨간 맛 (Red Flavor)</td>\n",
       "      <td>Red Velvet (레드벨벳)</td>\n",
       "      <td>95193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>사랑은 언제나 목마르다</td>\n",
       "      <td>유미</td>\n",
       "      <td>4836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>내 입술... 따뜻한 커피처럼</td>\n",
       "      <td>샵</td>\n",
       "      <td>3972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>오늘 헤어졌어요</td>\n",
       "      <td>윤하 (YOUNHA)</td>\n",
       "      <td>2428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>희재</td>\n",
       "      <td>성시경</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>이별살이</td>\n",
       "      <td>린</td>\n",
       "      <td>1190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             날짜                 노래                           가수   좋아요 수\n",
       "0    2020-05-01              Toxic      Glaceo, Cristina Lizzul  481718\n",
       "1    2020-05-01      Wasted Summer      teamwork, Loote, John K  283256\n",
       "2    2020-05-01          Lie To Me  Marphil, Yann Muller, Sylow  182396\n",
       "3    2020-05-01            Freedom               Kygo, Zak Abel  181091\n",
       "4    2020-05-01  빨간 맛 (Red Flavor)            Red Velvet (레드벨벳)   95193\n",
       "..          ...                ...                          ...     ...\n",
       "200  2020-06-10       사랑은 언제나 목마르다                           유미    4836\n",
       "201  2020-06-10   내 입술... 따뜻한 커피처럼                            샵    3972\n",
       "202  2020-06-10           오늘 헤어졌어요                  윤하 (YOUNHA)    2428\n",
       "203  2020-06-10                 희재                          성시경    1391\n",
       "204  2020-06-10               이별살이                            린    1190\n",
       "\n",
       "[205 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
