{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 날씨 데이터 크롤링\n",
    "\n",
    "출처: https://www.data.go.kr/  \n",
    "ASOS 종관기상관측 데이터 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시간별자료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode, unquote, quote_plus\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key='13nWfyvckU06jS8j02cgKEde9gF7%2B9BZ%2BOFcpgpuu%2FnNRbR64QYGlNEzN7b%2F9D4RI3uFKkJ97YT9mf5X3FMIUA%3D%3D'\n",
    "url=\"http://data.kma.go.kr/apiData/getData\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### api 설명서에 있는 활용가이드에서 요청/응답 메세지 예제를 확인한다\n",
    "\n",
    "### urlparse, parse_qs를 통해 파라미터로 나눠준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serviceKey': '13nWfyvckU06jS8j02cgKEde9gF7+9BZ+OFcpgpuu/nNRbR64QYGlNEzN7b/9D4RI3uFKkJ97YT9mf5X3FMIUA==',\n",
       " 'numOfRows': '10',\n",
       " 'pageNo': '1',\n",
       " 'dataCd': 'ASOS',\n",
       " 'dateCd': 'HR',\n",
       " 'stnIds': '108',\n",
       " 'schListCnt': '10',\n",
       " 'endDt': '20200101',\n",
       " 'endHh': '01',\n",
       " 'startHh': '01',\n",
       " 'startDt': '20100101',\n",
       " 'dataType': 'JSON'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "url = urlparse(\"http://apis.data.go.kr/1360000/AsosHourlyInfoService/getWthrDataList?serviceKey=13nWfyvckU06jS8j02cgKEde9gF7%2B9BZ%2BOFcpgpuu%2FnNRbR64QYGlNEzN7b%2F9D4RI3uFKkJ97YT9mf5X3FMIUA%3D%3D&numOfRows=10&pageNo=1&dataCd=ASOS&dateCd=HR&stnIds=108&schListCnt=10&endDt=20200101&endHh=01&startHh=01&startDt=20100101&dataType=JSON\")\n",
    "par_dic = parse_qs(url.query)\n",
    "for key in par_dic:\n",
    "    par_dic[key] = par_dic[key][0]\n",
    "par_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_hourly_data(start_date, start_hour,end_date,end_hour):\n",
    "    start_date=start_date\n",
    "    start_hour=start_hour\n",
    "    end_date=end_date\n",
    "    end_hour=end_hour\n",
    "    url='http://apis.data.go.kr/1360000/AsosHourlyInfoService/getWthrDataList'\n",
    "\n",
    "    \n",
    "    params={'serviceKey': '13nWfyvckU06jS8j02cgKEde9gF7+9BZ+OFcpgpuu/nNRbR64QYGlNEzN7b/9D4RI3uFKkJ97YT9mf5X3FMIUA==',\n",
    "     'numOfRows': '10',\n",
    "     'pageNo': '1',\n",
    "     'dataCd': 'ASOS',\n",
    "     'dateCd': 'HR',\n",
    "     'stnIds': '108',\n",
    "     'schListCnt': '10',\n",
    "     'endDt': end_date,\n",
    "     'endHh': end_hour,\n",
    "     'startHh': start_hour,\n",
    "     'startDt': start_date,\n",
    "     'dataType': 'JSON'\n",
    "           }\n",
    "\n",
    "    resp = requests.get(url, params=params)\n",
    "    #result= json.loads(resp.text)\n",
    "\n",
    "    return resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': {'header': {'resultCode': '00', 'resultMsg': 'NORMAL_SERVICE'},\n",
       "  'body': {'dataType': 'JSON',\n",
       "   'items': {'item': [{'tm': '2020-06-05 08:00',\n",
       "      'rnum': '1',\n",
       "      'stnId': '108',\n",
       "      'ta': 19.9,\n",
       "      'taQcflg': '',\n",
       "      'rn': 0.0,\n",
       "      'rnQcflg': '',\n",
       "      'ws': 2.2,\n",
       "      'wsQcflg': '',\n",
       "      'wd': 320,\n",
       "      'wdQcflg': '',\n",
       "      'hm': 86,\n",
       "      'hmQcflg': '',\n",
       "      'pv': 19.9,\n",
       "      'td': 17.4,\n",
       "      'pa': 998.0,\n",
       "      'paQcflg': '',\n",
       "      'ps': 1007.9,\n",
       "      'psQcflg': '',\n",
       "      'ss': 0.1,\n",
       "      'ssQcflg': '',\n",
       "      'icsr': 0.52,\n",
       "      'dsnw': 0.0,\n",
       "      'hr3Fhsc': 0.0,\n",
       "      'dc10Tca': 10,\n",
       "      'dc10LmcsCa': 10,\n",
       "      'clfmAbbrCd': 'St',\n",
       "      'lcsCh': 6,\n",
       "      'vs': 507,\n",
       "      'gndSttCd': 0,\n",
       "      'dmstMtphNo': '19',\n",
       "      'ts': 24.8,\n",
       "      'tsQcflg': '',\n",
       "      'm005Te': 21.5,\n",
       "      'm01Te': 22.3,\n",
       "      'm02Te': 21.7,\n",
       "      'm03Te': 22.1,\n",
       "      'stnNm': '서울'},\n",
       "     {'tm': '2020-06-05 09:00',\n",
       "      'rnum': '2',\n",
       "      'stnId': '108',\n",
       "      'ta': 21.0,\n",
       "      'taQcflg': '',\n",
       "      'rn': 0.0,\n",
       "      'rnQcflg': '',\n",
       "      'ws': 1.5,\n",
       "      'wsQcflg': '',\n",
       "      'wd': 270,\n",
       "      'wdQcflg': '',\n",
       "      'hm': 77,\n",
       "      'hmQcflg': '',\n",
       "      'pv': 19.1,\n",
       "      'td': 16.8,\n",
       "      'pa': 998.0,\n",
       "      'paQcflg': '',\n",
       "      'ps': 1007.9,\n",
       "      'psQcflg': '',\n",
       "      'ss': 0.2,\n",
       "      'ssQcflg': '',\n",
       "      'icsr': 1.23,\n",
       "      'dsnw': 0.0,\n",
       "      'hr3Fhsc': 0.0,\n",
       "      'dc10Tca': 7,\n",
       "      'dc10LmcsCa': 7,\n",
       "      'clfmAbbrCd': 'Sc',\n",
       "      'lcsCh': 7,\n",
       "      'vs': 681,\n",
       "      'gndSttCd': 0,\n",
       "      'dmstMtphNo': '19',\n",
       "      'ts': 29.7,\n",
       "      'tsQcflg': '',\n",
       "      'm005Te': 22.4,\n",
       "      'm01Te': 22.2,\n",
       "      'm02Te': 22.0,\n",
       "      'm03Te': 22.0,\n",
       "      'stnNm': '서울'}]},\n",
       "   'pageNo': 1,\n",
       "   'numOfRows': 10,\n",
       "   'totalCount': 2}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=get_hourly_data('20200605','08','20200605','09')\n",
    "json.loads(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일별데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serviceKey': '13nWfyvckU06jS8j02cgKEde9gF7+9BZ+OFcpgpuu/nNRbR64QYGlNEzN7b/9D4RI3uFKkJ97YT9mf5X3FMIUA==',\n",
       " 'numOfRows': '10',\n",
       " 'pageNo': '1',\n",
       " 'dataCd': 'ASOS',\n",
       " 'dateCd': 'DAY',\n",
       " 'startDt': '20100101',\n",
       " 'endDt': '20100102',\n",
       " 'stnIds': '108'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "url = urlparse(\"http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey=13nWfyvckU06jS8j02cgKEde9gF7%2B9BZ%2BOFcpgpuu%2FnNRbR64QYGlNEzN7b%2F9D4RI3uFKkJ97YT9mf5X3FMIUA%3D%3D&numOfRows=10&pageNo=1&dataCd=ASOS&dateCd=DAY&startDt=20100101&endDt=20100102&stnIds=108\")\n",
    "par_dic = parse_qs(url.query)\n",
    "for key in par_dic:\n",
    "    par_dic[key] = par_dic[key][0]\n",
    "par_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_data(start_date,end_date):\n",
    "    start_date=start_date\n",
    "    end_date=end_date\n",
    "    url='http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList'\n",
    "\n",
    "    \n",
    "    params={'serviceKey': unquote('13nWfyvckU06jS8j02cgKEde9gF7%2B9BZ%2BOFcpgpuu%2FnNRbR64QYGlNEzN7b%2F9D4RI3uFKkJ97YT9mf5X3FMIUA%3D%3D'),\n",
    "            'numOfRows': '200',\n",
    "            'pageNo': '1',\n",
    "            'dataCd': 'ASOS',\n",
    "            'dateCd': 'DAY',\n",
    "            'startDt': start_date,\n",
    "            'endDt': end_date,\n",
    "            'stnIds': '108',\n",
    "            'dataType':'JSON'\n",
    "           }\n",
    "\n",
    "    resp = requests.get(url, params=params)\n",
    "    result= json.loads(resp.text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_DataFrame(result):\n",
    "    total_data=result['response']['body']['items']['item']\n",
    "#     print(total_data)\n",
    "    result = {'날짜':[],\n",
    "              '최저기온':[],\n",
    "              '최고기온':[],\n",
    "              '비':[],\n",
    "              '강수량':[],\n",
    "              '옷차림' : []\n",
    "             }\n",
    "\n",
    "        \n",
    "    for data in total_data:\n",
    "        result['날짜'].append(data['tm'])\n",
    "        result['최저기온'].append(data['minTa'])\n",
    "        result['최고기온'].append(data['maxTa'])\n",
    "        if data['sumRn']>0:\n",
    "            result['비'].append('O')\n",
    "        else:\n",
    "            result['비'].append('X')\n",
    "        result['강수량'].append(data['sumRn'])\n",
    "        \n",
    "        avg = data['avgTa'] \n",
    "        if avg >= 28:\n",
    "            clothes = '나시티 / 반바지 / 민소매 / 원피스'\n",
    "        elif avg >= 23:\n",
    "            clothes = '반팔 / 얇은 셔츠 / 얇은 긴팔 / 반바지 / 면바지'\n",
    "        elif avg >= 20:\n",
    "            clothes = '긴팔티 / 가디건 / 후드티 / 면바지 / 슬랙스 / 청바지'\n",
    "        elif avg >= 17:\n",
    "            clothes = '니트 / 가디건 / 후드티 / 맨투맨 / 면바지 / 슬랙스 / 청바지'\n",
    "        elif avg >= 12:\n",
    "            clothes = '자켓 / 셔츠 / 가디건 / 간절기 외투'\n",
    "        elif avg >= 9:\n",
    "            clothes = '트렌치 코트 / 간절기 외투 / 여러겹 껴입기'\n",
    "        elif avg >= 6:\n",
    "            clothes = '코트 / 가죽자켓'\n",
    "        else:\n",
    "            clothes = '겨울 옷(야상, 패딩, 목도리 등등 다)'\n",
    "        \n",
    "        result['옷차림'].append(clothes)\n",
    "    df=pd.DataFrame(result)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_today(data):\n",
    "    clothes_list=[]\n",
    "    url = 'https://www.weatheri.co.kr/forecast/forecast01.php'\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.content, from_encoding='utf-8')\n",
    "    attrs={'width':'615',\n",
    "      'border':'0',\n",
    "      'cellpadding':'1',\n",
    "      'cellspacing':'1',\n",
    "       'bgcolor':'#BCBFC2'\n",
    "      }\n",
    "    inner_table = soup.find('table',attrs=attrs)\n",
    "    date = inner_table.select('td b')[0].text\n",
    "    date = '2020-{0}-{1}'.format(date.split()[0][:2],date.split()[1][:2])\n",
    "    high = inner_table.select('table tr td b font')[0].text\n",
    "    high = high.replace('˚C','')\n",
    "    low = inner_table.select('table tr td b font')[0].text\n",
    "    low = low.replace('˚C','')\n",
    "    sum_rain=inner_table.select('table tr td font')[-1].text\n",
    "    if sum_rain !='- mm':\n",
    "        rain='O',\n",
    "        sum_rain = 0\n",
    "    else:\n",
    "        rain='X'\n",
    "        sum_rain.split()[1][:-2]\n",
    "    avg = (int(high)+int(low))/2\n",
    "    if avg >= 28:\n",
    "        clothes = '나시티 / 반바지 / 민소매 / 원피스'\n",
    "    elif avg >= 23:\n",
    "        clothes = '반팔 / 얇은 셔츠 / 얇은 긴팔 / 반바지 / 면바지'\n",
    "    elif avg >= 20:\n",
    "        clothes = '긴팔티 / 가디건 / 후드티 / 면바지 / 슬랙스 / 청바지'\n",
    "    elif avg >= 17:\n",
    "        clothes = '니트 / 가디건 / 후드티 / 맨투맨 / 면바지 / 슬랙스 / 청바지'\n",
    "    elif avg >= 12:\n",
    "        clothes = '자켓 / 셔츠 / 가디건 / 간절기 외투'\n",
    "    elif avg >= 9:\n",
    "        clothes = '트렌치 코트 / 간절기 외투 / 여러겹 껴입기'\n",
    "    elif avg >= 6:\n",
    "        clothes = '코트 / 가죽자켓'\n",
    "    else:\n",
    "        clothes = '겨울 옷(야상, 패딩, 목도리 등등 다)'\n",
    "    clothes_list.append(clothes)     \n",
    "    \n",
    "    new_data=pd.DataFrame({'날짜':[date],\n",
    "             '최저기온':[low],\n",
    "             '최고기온':[high],\n",
    "             '비':[rain],\n",
    "             '강수량':[sum_rain],\n",
    "             '옷차림':clothes_list})\n",
    "    \n",
    "    data = data.append(new_data,ignore_index=True)\n",
    "    print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             날짜  최저기온  최고기온  비   강수량                                옷차림\n",
      "0    2020-01-01  -6.5   0.3  O   0.1             겨울 옷(야상, 패딩, 목도리 등등 다)\n",
      "1    2020-01-02  -0.7   3.8  X     0             겨울 옷(야상, 패딩, 목도리 등등 다)\n",
      "2    2020-01-03  -3.4   4.6  X     0             겨울 옷(야상, 패딩, 목도리 등등 다)\n",
      "3    2020-01-04  -2.8   6.1  X     0             겨울 옷(야상, 패딩, 목도리 등등 다)\n",
      "4    2020-01-05  -3.2   6.6  X     0             겨울 옷(야상, 패딩, 목도리 등등 다)\n",
      "..          ...   ...   ... ..   ...                                ...\n",
      "154  2020-06-03  17.6  28.4  X     0  긴팔티 / 가디건 / 후드티 / 면바지 / 슬랙스 / 청바지\n",
      "155  2020-06-04  19.7  26.5  O   0.2  긴팔티 / 가디건 / 후드티 / 면바지 / 슬랙스 / 청바지\n",
      "156  2020-06-05  18.4  28.7  X     0     반팔 / 얇은 셔츠 / 얇은 긴팔 / 반바지 / 면바지\n",
      "157  2020-06-06  19.2  30.9  X     0     반팔 / 얇은 셔츠 / 얇은 긴팔 / 반바지 / 면바지\n",
      "158  2020-06-08    30    30  X  - mm              나시티 / 반바지 / 민소매 / 원피스\n",
      "\n",
      "[159 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "result=get_daily_data('20200101','20200606')\n",
    "\n",
    "output=data_to_DataFrame(result)\n",
    "\n",
    "d=append_today(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_excel('weather_crawling.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
